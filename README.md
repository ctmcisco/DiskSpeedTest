# DiskSpeedTest

Utility to automate iterative IO performance tests.  
The tool includes two tests, one using the [DiskSpd](https://github.com/microsoft/diskspd) utility, and another iterating bulk file create, read, and delete operations.  

_**Use at your own risk, the tool can be destructive.**_

## License

[![GitHub](https://img.shields.io/github/license/ptr727/DiskSpeedTest)](https://github.com/ptr727/DiskSpeedTest/blob/master/LICENSE)

## Project

Code is on [GitHub](https://github.com/ptr727/DiskSpeedTest)

## Usage

- I am not publishing binaries, you need to compile your own binary. You will need the [.NET Core 3.1 SDK](https://dotnet.microsoft.com/download), and [Visual Studio 2019](https://visualstudio.microsoft.com/downloads/) or [Visual Studio Code](https://code.visualstudio.com/download).
- Clone and compile the code from [GitHub](https://github.com/ptr727/DiskSpeedTest).
- Download [DiskSpd](https://aka.ms/diskspd), and place the `diskspd.exe` binary in the path or the working directory.
- Create a JSON config file with the required test parameters.
- Specify the path to the JSON config on the commandline, e.g. `DiskSpeedTest.exe DiskSpeedTest.json`.
- Analyze the CSV result files.

## JSON Config File

```json
{
  // Add a timestamp to the result output filenames
  "timestampresultfile": false,
  // DiskSpeedTest config
  "diskspeedtest": {
    // Enable this test
    "enabled": true,
    // Output CSV file
    "resultfile": "DiskSpeedResult.csv",
    // Test targets, full path and filename, directory must exist, file will be created
    "targets": [
      "C:\\Temp\\DiskSpeedData.dat",
      "\\\\Server\\Share\\DiskSpeedData.dat"
    ],
    // File size of test target in bytes
    "targetsize": 68719476736,
    // Block size in bytes, automatically generated by doubling the beginning value until the end size is reached
    "blocksizebegin": 4096,
    "blocksizeend": 2097152,
    // Warmup time in seconds, do IO but don't use the values in computed results
    "warmuptime": 30,
    // Test time in seconds
    "testtime": 120,
    // Time to rest between test runs
    "resttime": 0
  },
  // FileIterationTest config
  "fileiterationtest": {
    // Enable this test
    "enabled": true,
    // Output CSV file
    "resultfile": "FileIterationResult.csv",
    // Test targets, full path, directory will be created, contents will be deleted
    "targets": [
      "C:\\Temp\\FileIteration",
      "\\\\Server\\Share\\FileIteration"
    ],
    // Folder depth for recursion
    "folderdepth": 2,
    // Folders per folder
    "foldersperfolder": 2,
    // Files per folder
    "filesperfolder": 1000,
    // File size in bytes
    "filesize": 65536
  }
}
```

## CSV Output Files

### DiskSpeedTest CSV

`UTC, Target, FileSize, BlockSize, WriteRatio, ThreadCount, OutstandingOperations, WarmupTime, TestTime, Bytes, IOS`

### FileIterationTest CSV

`UTC, Target, FileSize, FolderDepth, FoldersPerFolder, FilesPerFolder, FolderCount, FileCount, CreateTime, ReadTime, DeleteTime`

## Notes

- I created the utility to help [troubleshoot](https://blog.insanegenius.com/2019/06/10/unraid-in-production-a-bit-rough-around-the-edges-and-terrible-smb-performance/) UnRaid v6.7.2 SMB performance issues.
- I added the file iteration test to help [troubleshoot](https://forums.unraid.net/bug-reports/stable-releases/680-smb-ver-4113-significant-performance-decrease-when-opening-files-in-folders-with-1000-files-in-them-r789/) Unraid v6.8.1 performance uissues when a folder contains a large number of files.
- DiskSpd will conditionally use privileged IO functions, so test results will  differ between running elevated or not, do not mix test results.
